{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40bcd3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, time\n",
    "import cv2, random\n",
    "import pickle, joblib\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import gurobipy as gp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from lib.tracking import Tracker\n",
    "from lib.qpthlocal.qp import QPFunction, QPSolvers\n",
    "from lib.utils import getIoU, interpolateTrack, interpolateTracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dd54ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOT16-02.pkl',\n",
       " 'MOT16-04.pkl',\n",
       " 'MOT16-05.pkl',\n",
       " 'MOT16-09.pkl',\n",
       " 'MOT16-10.pkl',\n",
       " 'MOT16-11.pkl',\n",
       " 'MOT16-13.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"reproduce_train_graph_MOT16/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f57c0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1011 samples in training set, 319 in validation set\n",
      "Used 379 samples in training set, 36 in validation set\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "train_data_list_full, val_data_list_full = [], []\n",
    "# root_data_path = \"data/train_data/\"\n",
    "root_data_path = \"reproduce_train_graph_MOT16_reidFeature/\"\n",
    "for file in os.listdir(root_data_path):\n",
    "    file_name = root_data_path + file\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data_list = pickle.load(f)\n",
    "        \n",
    "    if file.startswith('MOT16-09') or file.startswith('MOT16-13'):\n",
    "        val_data_list_full = val_data_list_full + data_list\n",
    "    else:\n",
    "        train_data_list_full = train_data_list_full + data_list\n",
    "        \n",
    "print('Total {} samples in training set, {} in validation set'.format(\n",
    "                     len(train_data_list_full),len(val_data_list_full)))\n",
    "\n",
    "train_data_list, val_data_list = [], []\n",
    "for ind in range(len(train_data_list_full)):\n",
    "    if train_data_list_full[ind].x.shape[0] < 200: #Avoid too big graph\n",
    "        train_data_list.append(train_data_list_full[ind])\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "for ind in range(len(val_data_list_full)):\n",
    "    if val_data_list_full[ind].x.shape[0] < 200:\n",
    "        val_data_list.append(val_data_list_full[ind])\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print('Used {} samples in training set, {} in validation set'.format(len(train_data_list), len(val_data_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ea127f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(6,6), nn.ReLU(), nn.Linear(6,1))\n",
    "        # self.fc = nn.Sequential(nn.Linear(6,1))\n",
    "    def forward(self, data):\n",
    "        # x = self.fc(data.edge_attr)\n",
    "        x = self.fc(torch.tensor(data.edge_attr, dtype=torch.float32))\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "tracker = Tracker(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3221f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 it [0/379] pr [0.59-0.60] obj [-32.98/-76.00] mse 0.0931 mse edge 0.1452 ce 0.829 auc 0.758 ham 0.100\n",
      "epoch 0 it [1/379] pr [0.58-0.61] obj [-59.01/-135.00] mse 0.0693 mse edge 0.0904 ce 0.858 auc 0.764 ham 0.081\n",
      "epoch 0 it [2/379] pr [0.58-0.61] obj [-67.53/-156.00] mse 0.0641 mse edge 0.0790 ce 0.868 auc 0.561 ham 0.096\n",
      "epoch 0 it [3/379] pr [0.58-0.61] obj [-55.91/-126.00] mse 0.0759 mse edge 0.1029 ce 0.860 auc 0.531 ham 0.143\n",
      "epoch 0 it [4/379] pr [0.58-0.66] obj [-66.04/-147.00] mse 0.0681 mse edge 0.0882 ce 0.875 auc 0.590 ham 0.077\n",
      "epoch 0 it [5/379] pr [0.59-0.60] obj [-47.17/-104.00] mse 0.0795 mse edge 0.1070 ce 0.848 auc 0.803 ham 0.097\n",
      "epoch 0 it [6/379] pr [0.59-0.62] obj [-49.70/-114.00] mse 0.0788 mse edge 0.1079 ce 0.856 auc 0.645 ham 0.086\n",
      "epoch 0 it [7/379] pr [0.58-0.62] obj [-62.19/-140.00] mse 0.0690 mse edge 0.0911 ce 0.864 auc 0.637 ham 0.091\n",
      "epoch 0 it [8/379] pr [0.59-0.61] obj [-70.16/-158.00] mse 0.0614 mse edge 0.0752 ce 0.867 auc 0.774 ham 0.069\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.1\n",
    "train_list, val_list = [], [] #Used for login loss, AUC, etc.\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "for epoch in range(0, 25):\n",
    "    np.random.shuffle(train_data_list)\n",
    "    for itr in range(len(train_data_list)):\n",
    "        data = train_data_list[itr]\n",
    "        A_eq, b_eq, A_ub, b_ub, x_gt = tracker.build_constraint_training(data)\n",
    "        \n",
    "        A, b = torch.from_numpy(A_eq).float(), torch.from_numpy(b_eq).float().flatten()\n",
    "        G, h = torch.from_numpy(A_ub).float(), torch.from_numpy(b_ub).float().flatten()\n",
    "\n",
    "        num_nodes = A.shape[0] // 2\n",
    "        Q = gamma * torch.eye(A.shape[1])\n",
    "\n",
    "        prob = net(data)\n",
    "        prob = torch.clamp(prob, min=1e-7, max=1-1e-7)                       #Predicted matching probability\n",
    "        prob_numpy = prob.detach().numpy()                                   #Predicted matching probability in np\n",
    "        auc = sklearn.metrics.roc_auc_score(x_gt[num_nodes*3: ], prob_numpy) #Area under the ROC Curve\n",
    "\n",
    "        c_det, c_entry, c_exit = -1 * torch.ones(num_nodes), torch.ones(num_nodes), torch.ones(num_nodes)\n",
    "        c_pred = -1 * torch.log(prob).squeeze()\n",
    "        c_pred = torch.cat([c_det, c_entry, c_exit, c_pred])\n",
    "\n",
    "        model_params_quad = tracker.make_gurobi_model_tracking(G.numpy(),h.numpy(),A.numpy(),b.numpy(),Q.numpy())\n",
    "        x = QPFunction(verbose=False, solver=QPSolvers.GUROBI, maxIter=50, \n",
    "                       model_params=model_params_quad)(Q, c_pred, G, h, A, b)\n",
    "\n",
    "        loss = nn.MSELoss()(x.flatten(), torch.from_numpy(x_gt))\n",
    "        loss_edge = nn.MSELoss()(x[:, num_nodes*3:].flatten(), torch.from_numpy(x_gt[num_nodes*3:]).float())\n",
    "\n",
    "        const_cost = 1\n",
    "        c_ = const_cost * (1 - x_gt[num_nodes*3:])\n",
    "        c_gt = torch.cat([c_pred[:num_nodes*3], torch.from_numpy(c_).float()]) #Ground truth cost\n",
    "\n",
    "        obj_gt = c_gt @ torch.from_numpy(x_gt).float()               #Ground truth objective value\n",
    "        obj_pred = c_pred @ x.squeeze() #Predicted objective value, should be close to GT objective value after training\n",
    "\n",
    "        bce = nn.BCELoss()(prob.flatten(), torch.from_numpy(x_gt[num_nodes*3:]).float())\n",
    "        x_sol = tracker.linprog(c_pred.detach().numpy(), A_eq, b_eq, A_ub, b_ub)\n",
    "        ham_loss = sklearn.metrics.hamming_loss(x_gt, x_sol)\n",
    "\n",
    "        train_list.append((loss.item(), loss_edge.item(), auc, bce.item()))\n",
    "        print('epoch {} it [{}/{}] pr [{:.2f}-{:.2f}] obj [{:.2f}/{:.2f}] mse {:.4f} mse edge {:.4f} ce {:.3f} \\\n",
    "auc {:.3f} ham {:.3f}'.format(epoch, itr, len(train_data_list), prob.min(), prob.max(), \n",
    "                              obj_pred, obj_gt, loss, loss_edge, bce, auc, ham_loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_edge.backward()\n",
    "        #bce.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Saving epoch {} ...\\n'.format(epoch))\n",
    "    torch.save(net.state_dict(), 'ckpt/mot16_reid_feature/epoch-{}.pth'.format(epoch))\n",
    "    \n",
    "    np.random.shuffle(val_data_list)\n",
    "    for itr in range(len(val_data_list)):\n",
    "        \n",
    "        val_data = val_data_list[itr]\n",
    "        A_eq, b_eq, A_ub, b_ub, x_gt = tracker.build_constraint_training(val_data)\n",
    "        \n",
    "        A, b = torch.from_numpy(A_eq).float(), torch.from_numpy(b_eq).float().flatten()\n",
    "        G, h = torch.from_numpy(A_ub).float(), torch.from_numpy(b_ub).float().flatten()\n",
    "\n",
    "        num_nodes = A.shape[0] // 2\n",
    "        Q = gamma * torch.eye(A.shape[1])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            prob = net(val_data)\n",
    "            prob = torch.clamp(prob, min=1e-7, max=1-1e-7)\n",
    "        \n",
    "        prob_numpy = prob.detach().numpy() #matching probability in numpy\n",
    "        auc = sklearn.metrics.roc_auc_score(x_gt[num_nodes*3: ], prob_numpy) #Area under the ROC Curve\n",
    "\n",
    "        c_det, c_entry, c_exit = -1 * torch.ones(num_nodes), torch.ones(num_nodes), torch.ones(num_nodes)\n",
    "        c_pred = -1 * torch.log(prob).squeeze()\n",
    "        c_pred = torch.cat([c_det, c_entry, c_exit, c_pred])\n",
    "\n",
    "        model_params_quad = tracker.make_gurobi_model_tracking(G.numpy(),h.numpy(),A.numpy(),b.numpy(),Q.numpy())\n",
    "        x = QPFunction(verbose=False, solver=QPSolvers.GUROBI, maxIter=50, \n",
    "                       model_params=model_params_quad)(Q, c_pred, G, h, A, b)\n",
    "\n",
    "        loss = nn.MSELoss()(x.flatten(), torch.from_numpy(x_gt))\n",
    "        loss_edge = nn.MSELoss()(x[:, num_nodes*3:].flatten(), torch.from_numpy(x_gt[num_nodes*3:]).float())\n",
    "\n",
    "        const_cost = 1\n",
    "        c_ = const_cost * (1 - x_gt[num_nodes*3:])\n",
    "        c_gt = torch.cat([c_pred[:num_nodes*3], torch.from_numpy(c_).float()]) #Ground truth cost\n",
    "\n",
    "        obj_gt = c_gt @ torch.from_numpy(x_gt).float()               #Ground truth objective value\n",
    "        obj_pred = c_pred @ x.squeeze() #Predicted objective value, should be close to GT objective value after training\n",
    "\n",
    "        bce = nn.BCELoss()(prob.flatten(), torch.from_numpy(x_gt[num_nodes*3:]).float())\n",
    "        x_sol = tracker.linprog(c_pred.detach().numpy(), A_eq, b_eq, A_ub, b_ub)\n",
    "        ham_loss = sklearn.metrics.hamming_loss(x_gt, x_sol)\n",
    "        val_list.append((loss.item(), loss_edge.item(), auc, bce.item()))\n",
    "        print('vepo {} it [{}/{}] pr [{:.2f}-{:.2f}] obj [{:.2f}/{:.2f}] mse {:.4f} mse edge {:.4f} ce {:.3f} \\\n",
    "auc {:.3f} ham {:.3f}'.format(epoch, itr, len(val_data_list), prob.min(), prob.max(), \n",
    "                              obj_pred, obj_gt, loss, loss_edge, bce, auc, ham_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f31f6-1f90-46d3-ba03-ed4d53ebe5af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29248d8-c153-4227-9920-34f7987ceed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae5e32-00c8-40a8-a334-ad3b6fb8302b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde01be-27c4-44cf-b3b0-62803c0aa8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af5edb44-938b-4746-8dee-0b564c4f72b5",
   "metadata": {},
   "source": [
    "# SHAP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ede7c97-4f7b-4aff-a7b1-42dc7261f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapNet(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(ShapNet, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(6,6), nn.ReLU(), nn.Linear(6,1))\n",
    "    def forward(self, x):\n",
    "        # x = self.fc(data.edge_attr)\n",
    "        x = self.fc(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37c800c3-c299-4677-a7e6-0c3f68149fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3611640/77365706.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load('ckpt/original/epoch_20.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ShapNet()\n",
    "net.load_state_dict(torch.load('ckpt/original/epoch_20.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca460b3a-2b6e-444e-ad63-a86496a78f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = net(torch.tensor(data_list[0].edge_attr, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cc54d773-64f7-4a26-b44d-63a0864dbf99",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of %f is significant compared to the scale of your model outputs, please post as a github issue, with a reproducible example so we can debug it. Used framework: pytorch - Max. diff: 0.643880556570366 - Tolerance: 0.01",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# explainer = shap.DeepExplainer(net, torch.tensor(data_list[0].edge_attr, dtype=torch.float32))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LPT/lib/python3.9/site-packages/shap/explainers/_deep/__init__.py:164\u001b[0m, in \u001b[0;36mDeepExplainer.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LPT/lib/python3.9/site-packages/shap/explainers/_deep/deep_pytorch.py:226\u001b[0m, in \u001b[0;36mPyTorchDeep.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    224\u001b[0m             model_output_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39mX)\n\u001b[0;32m--> 226\u001b[0m     \u001b[43m_check_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_phis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output_phis, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m# in this case we have multiple inputs and potentially multiple outputs\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output_phis[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/LPT/lib/python3.9/site-packages/shap/explainers/_deep/deep_utils.py:26\u001b[0m, in \u001b[0;36m_check_additivity\u001b[0;34m(explainer, model_output_values, output_phis)\u001b[0m\n\u001b[1;32m     22\u001b[0m         diffs \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m output_phis[t][i]\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, output_phis[t][i]\u001b[38;5;241m.\u001b[39mndim)))\n\u001b[1;32m     24\u001b[0m maxdiff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(diffs)\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m maxdiff \u001b[38;5;241m<\u001b[39m TOLERANCE, (\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe SHAP explanations do not sum up to the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms output! This is either because of a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrounding error or because an operator in your computation graph was not fully supported. If \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe sum difference of \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m is significant compared to the scale of your model outputs, please post \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas a github issue, with a reproducible example so we can debug it. Used framework: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexplainer\u001b[38;5;241m.\u001b[39mframework\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Max. diff: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaxdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Tolerance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTOLERANCE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of %f is significant compared to the scale of your model outputs, please post as a github issue, with a reproducible example so we can debug it. Used framework: pytorch - Max. diff: 0.643880556570366 - Tolerance: 0.01"
     ]
    }
   ],
   "source": [
    "# explainer = shap.DeepExplainer(net, torch.tensor(data_list[0].edge_attr, dtype=torch.float32))\n",
    "shap_values = explainer.shap_values(torch.tensor(data_list[0].edge_attr[:100], dtype=torch.float32), check_additivity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67ecc924-1390-42c1-b180-d537f9e0d6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0.9967],\n",
       "        [    0.0002],\n",
       "        [    0.0000],\n",
       "        ...,\n",
       "        [    0.0016],\n",
       "        [    0.0010],\n",
       "        [    0.9962]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e77feb-1c32-495b-9da8-f84832e7d2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033213e0-771d-4d61-9c2a-45967e286d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d35f1-016a-46ae-8994-34ecd6748cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce151a-2816-4b62-87bf-31339d15e2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af84f4-0028-4b63-b239-2d2569ff757e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cae7aa-8706-4391-b1ea-549902f5d530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373ba85-b7a5-40e6-9857-9fc4f74b8fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "732a36bf-1034-496a-bf67-361511b75b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3611640/306972945.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load('ckpt/mot16_simple/epoch-20.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3524, -6.1803,  2.2318, -5.5801,  4.4129,  2.2822]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ShapNet()\n",
    "net.load_state_dict(torch.load('ckpt/mot1/epoch-20.pth'))\n",
    "net.fc[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585b1f1-e5a8-4f02-bc2b-3240d7fe4091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2fa40-8cb2-4848-85db-b95c669eafe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "973e14ad-4e4b-4b3c-8351-bc921eeaf4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapNet(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=6, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c90b8e-1af7-4b01-9aa3-a1fe8b0de358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LPT",
   "language": "python",
   "name": "lpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
